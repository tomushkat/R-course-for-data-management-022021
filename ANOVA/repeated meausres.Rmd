---
title: "Repeated Measures ANOVA"
author: "P-Value Data Analytics"
date: "3/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)   # Do not run
```

# Goal - testing differences in number of purchaes between January, February and March




# Libraries
```{r, warning=FALSE, message=FALSE}
pacman::p_load(tidyverse, effectsize)
```

## From the Git Hub

1) Go to the GitHub repository link where you have the CSV file.
2) Click on the **raw** option present on the top right of the data.
3) This will open a new window in the browser.
4) The link should be like **https://raw.githubusercontent.com/..**.
5) You have to use this link to download csv file from Github.

```{r, warning=FALSE, message=FALSE}
URL <- c('https://raw.githubusercontent.com/tomushkat/R-course-for-data-management-022021/main/anovaData.csv')
dataGit <- read_csv(url(URL))
```

# Preparing data
## What months are there in the data (the time-variable)?
```{r, warning=FALSE, message=FALSE}
table(dataGit$Month)
round(100 * table(dataGit$Month) / length(na.omit(dataGit$Month)), 1)
```

## Show the levels
```{r, warning=FALSE, message=FALSE}
levels(as.factor(dataGit$Month))
```

## Change levels to chronological order 
```{r, warning=FALSE, message=FALSE}
dataGit <- dataGit %>% 
  mutate(Month = as.factor(Month),
    Month = ordered(Month, levels = c("January", "February", 'March')))

levels(dataGit$Month)
```

## If we have inconsistency with the data, do not forget to remove cases with not enough observations.
```{r, warning=FALSE, message=FALSE}

data <- dataGit
varString <- c('ID')
N <- 3


removeSingles <- function(data, varString, N){
  
  # This function removes rows from the data set that their target variable does not repeat N time.
  # The function get the (1) data set, (2) the name of the variables as a string/character, and (3) the number of correct repetitions
  
  require(tidyverse)

  
  dataSet <- as.data.frame(table(data[, varString]))
  dataSet <- dataSet %>% 
    mutate(Logical = ifelse(Freq == N, 1, 0))
  dimnames(dataSet)[[2]] <- c(varString, 'Freq', 'Logical' )
  data1 <- merge(data, dataSet, by = varString, all = TRUE)
  data2 <- data1 %>%
    filter(Logical > 0) %>% 
    mutate(Freq = NULL,
           Logical = NULL)
  
   return(data2)
}

dataGit <- removeSingles(dataGit, 'ID', 3)

```


## Do not forget to examine the dependent and independent variables, remove outliers, and test the normality of the observations. 

## Summary statistics
Here you should group by and summaries **twice**.

```{r, warning=FALSE, message=FALSE}
dataGit %>% 
  drop_na(ID, Month, Purchase) %>% 
  group_by(ID, Month) %>% 
  summarise(meanPurchase = mean(Purchase)) %>% 
  group_by(Month) %>%
  summarise(Mean = round(mean(meanPurchase), 2),
            SD   = round(sd(meanPurchase), 2),
            N    = length(meanPurchase))
```



# Hypothesis testing
FIrst we convert the ID into factor using the **mutate** and **as.factor** commands. 
Then we perform the repeated measures ANOVA.
```{r, warning=FALSE, message=FALSE}
dataGit <- dataGit %>% 
  mutate(ID = as.factor(ID))

Model <- aov(Purchase ~ Month + Error(ID / Month), data = dataGit)
summary(Model)
```

### Effect size - eta squered
The effect size is calculated using the **effectsize** command from the package **effectsize**. Indicating the type is not mandatory.
```{r, warning=FALSE, message=FALSE}
effectsize(Model, type = 'eta')      # effectsize
```

### Post hoc pairwise comparisons
The pairwise.t.test conduced all the pairwise comparisons. The X item is the response vector and the g item is the grouping vector or factor.
The **p.adjust.method** is the correction method. **paired** should be TRUE, the data should be organized (sorted)

```{r, warning=FALSE, message=FALSE}
pairwise.t.test(x = dataGit$Purchase, g = dataGit$Month,
                  p.adjust.method = "bonferroni", paired = TRUE)

 dataGit %>%
   drop_na(ID, Month, Purchase) %>%
   group_by(ID, Month) %>%
   summarise(meanPurchase = mean(Purchase)) %>%
   group_by(Month) %>%
   summarise(Mean = round(mean(meanPurchase), 2),
             SD   = round(sd(meanPurchase), 2),
             N    = length(meanPurchase))
```



## Visualization
Here you should group by and summaries twice one time prior the figure coding.

```{r, warning=FALSE, message=FALSE}
dataGit %>% 
    drop_na(ID, Month, Purchase) %>% 
  group_by(ID, Month) %>% 
  summarise(meanPurchase = mean(Purchase)) %>% 
  ggplot(aes(x = Month, y = meanPurchase, fill = Month)) + 
    geom_bar(stat = 'summary', position = position_dodge()) +
      geom_jitter(aes(x = Month, y = meanPurchase, fill = Month), color = 'blue') + 
    stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), 
               geom = "errorbar", color = "red", width = 0.2) +
    stat_summary(fun.y = mean, geom = "point", color = "red") +
    theme_classic() + ylab('Purchase') + xlab('Month') + 
    ggtitle('RM model bar plot: Purchase ~ Month') + theme(plot.title = element_text(hjust = 0.5)) 
```

