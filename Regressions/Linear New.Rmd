---
title: "Linear Regression new"
author: "P-value Data Analytics"
date: "4/13/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)  # Do not run
```

# Goal - Assessing the multivariante correlation between ltv and (1) single and (2) multiple variables  

# Libraries
```{r, warning=FALSE, message=FALSE}
pacman::p_load(tidyverse, lmtest, estimatr, skimr, faraway, apaTables)
```


# Uploading a data set from the Git Hub

1) Go to the GitHub repository link where you have the CSV file.
2) Click on the **raw** option present on the top right of the data.
3) This will open a new window in the browser.
4) The link should be like **https://raw.githubusercontent.com/..**.
5) You have to use this link to download csv file from Github.

```{r, warning=FALSE, message=FALSE}
URL <- c('https://raw.githubusercontent.com/tomushkat/R-course-for-data-management-022021/main/Smart%20segmentation%20values%20DATA%20240321.csv')
dataGit <- read_csv(url(URL))
```


# Exploring the data set and removing outlaiers

Following the data set exploring, we can see that for some reason the **spin_habit_group** variable was uploaded as a **character type**. Therefore we need to transform it to a **numeric type**.

```{r, warning=FALSE, message=FALSE}
view(dataGit)
head(dataGit, 10)
tail(dataGit, 10)
str(dataGit)
skim(dataGit)

dataGit <- dataGit %>% 
  mutate(spin_habit_group = as.numeric(spin_habit_group))
```


Using the **continuousOutliers** command we can remove outliers from all the continuous variables.
First we create a new data set named **cleanData** which is a copy of the original data set.
The changes will be on the **cleanData** data set. 
Using a **for loop** we can use the function for each variable separately. 


Note: If we want to use the spin_habit_group, weekly_play_days, bet_habit_group, daily_wager_group, cz_group as ordinal variables and not as continuous we cannot remove its outliers.
```{r, warning=FALSE, message=FALSE}
continuousOutliers <- function(data, lowerBound = 3, upperBound = 3){
  
  # This function takes a vector, and replace observations that are smaller or bigger than the lower/upper bounds * standard deviations with NA
  
  Mean   <- mean(data, na.rm = TRUE)
  SD     <- sd(data, na.rm = TRUE)
  High   <- Mean + upperBound * SD # Upper Range  
  Low    <- Mean - lowerBound * SD # Lower Range
  Final  <- ifelse(data > High | data < Low, NA, data)
  
  return(Final)
  
}


cleanData <- dataGit %>% filter(ltv > 0)

Variables <- c('ltv', 'spin_habit_group', 'weekly_play_days', 'bet_habit', 'bet_habit_group', 'daily_wager_group', 'cz_group')

for(varName in Variables){
  cleanData[, varName] <- continuousOutliers(unlist(cleanData[, varName]))
}
```


# Linear regression for a simple independet variable - predicting ltv by bet habit/bet habit group

First we select the only relevant variables, while creating a new data set naming **newData**.
```{r, warning=FALSE, message=FALSE}
newData <- cleanData %>% 
  select(bet_habit_group, ltv) %>% 
  mutate(DV = ltv,
         IV = bet_habit_group) %>% 
  drop_na()

skim(newData)
```

Than, we plot a figure the describe the relation between the dependent and the independent variables.
```{r, warning=FALSE, message=FALSE}
newData %>% 
  ggplot(aes(x =  IV, y = DV)) + 
  geom_point() +
  geom_smooth(method = 'lm') + 
  theme_classic() + 
  xlab('Independent variable') + ylab('Dependent variable')
```

## Testing the assumptions
### Linearity

## Performing linear regression 
Using the **lm_robust** command from the **estimatr** package we can perform a linear model. 
The type of the regression (Heteroskedasticity or Homoskedasticity) is determined using the *se_type*.
```{r, warning=FALSE, message=FALSE}
Model <- lm_robust(DV ~ IV, se_type = 'HC2', data = newData) # estimatr package
summary(Model)
```

### Standardized beta coeff 
For extracting the standardized beta coefficients we should scale the all data set, and perform the regression again.
```{r, warning=FALSE, message=FALSE}
scalednewData <- newData %>% 
  mutate(DV = scale(DV),
         IV = scale(IV))

Model1 <- lm_robust(DV ~ IV, se_type = 'HC2', data = scalednewData) # estimatr package
summary(Model1)

round(Model1$coefficients, 2)
```


### Visualization
We can plot and calculate the correlation between the fitted values and the dependent variable for accuracy testing.
```{r, warning=FALSE, message=FALSE}

newData$fitted <- Model$fitted.values

newData %>% 
  ggplot(aes(x = fitted, y = DV)) + 
  geom_point() +
  geom_smooth(method = 'lm') + 
  theme_classic() + 
  xlab('Fitted values') + ylab('Dependent variable')


cor.test(newData$DV, newData$fitted)
```

# Multivariable Linear regression - perdicting ltv by spin habit group, weekly play days, bet habit group, daily wager group and cz group
## Preparing the data set

First we select the relevant data.
```{r, warning=FALSE, message=FALSE}
newData <- cleanData %>% 
    select(ltv, spin_habit_group, weekly_play_days, bet_habit_group, daily_wager_group, cz_group) %>% 
    mutate(DV = ltv) %>% 
  drop_na()

skim(newData)
```


Using the median we can decide how to split the **weekly play days** into high and low subgroups (this is only for example, usually you will prefer to use the continuous variables).
However, it is highly recommended to use theory (prior information) for splitting the data set, and not only using the distribution.
```{r, warning=FALSE, message=FALSE}
hist(newData$weekly_play_days)
weekly_play_days_median <- median(newData$weekly_play_days)
weekly_play_days_median

newData <- newData %>% 
  mutate(weekly_play_days = ifelse(weekly_play_days <= weekly_play_days_median, 'Low', 'High'),
         weekly_play_days = as.factor(weekly_play_days))
```



## Testing assumptions
### Linearity
### Univariate correlations
```{r, warning=FALSE, message=FALSE}
newData %>% 
  mutate(weekly_play_days = ifelse(weekly_play_days == 'Low', 0, 1)) %>% 
  apa.cor.table()
```

## Performing linear regression
```{r, warning=FALSE, message=FALSE}
Model <- lm_robust(DV ~ spin_habit_group + weekly_play_days + bet_habit_group + cz_group + daily_wager_group, se_type = 'HC2', data = newData)

summary(Model)
```


### Standerlized beta coeff 
As before we should conduct the model again.
If you have characters as independent variables, we need to transform them to integers and than to into factors. 
```{r, warning=FALSE, message=FALSE}
scalednewData <- newData %>% 
  mutate(DV = scale(DV),
         spin_habit_group = scale(spin_habit_group),
         bet_habit_group = scale(bet_habit_group),
         cz_group = scale(cz_group),
         daily_wager_group = scale(daily_wager_group),
         weekly_play_days = ifelse(weekly_play_days == 'High', 0, 1),
         weekly_play_days = as.factor(scale(weekly_play_days)))

Model1 <- lm_robust(DV ~ spin_habit_group + weekly_play_days + bet_habit_group + cz_group + daily_wager_group, se_type = 'HC2', data = scalednewData) # estimatr package
summary(Model1)

round(Model1$coefficients, 2)
```

### Visualization

We can plot and calculate the correlation between the fitted values and the dependent variable for accuracy testing.
```{r, warning=FALSE, message=FALSE}
newData$fitted <- Model$fitted.values

newData %>% 
  ggplot(aes(x = fitted, y = DV)) + 
  geom_point() +
  geom_smooth(method = 'lm') + 
  theme_classic() + 
  xlab("Model's fitted values") + ylab('Dependent variable')
cor.test(newData$DV, newData$fitted)
```





## Visualization
Using the **ggplot** command we can describe all the variables on a single figure. 
Note: try to use the command **shape** if you have an additional ordinal (factor) variable.
```{r, warning=FALSE, message=FALSE}
newData %>% 
  ggplot(aes(x = spin_habit_group, y = DV)) + 
  geom_point(aes(color = weekly_play_days, size = bet_habit_group, alpha = daily_wager_group)) +
  facet_grid(~cz_group) + 
  theme_classic() + 
  ylab('Dependent variable')
```


### Detecting Multicoliniarity

For detecting multicoliniarity we should first ran the model using the **lm** command.
Than, using the **vif** command from the **faraway** package we can test whether there is any Variance Inflation Factor (VIF) greater than 10.
As we can see, **daily wager group**  has VIF value greater than 10. Therefore, we should exclude it from the analysis.
```{r, warning=FALSE, message=FALSE}
Model <- lm(DV ~ spin_habit_group + weekly_play_days + bet_habit_group + daily_wager_group + cz_group, data = newData) 

vif(Model) # faraway package

Model <- lm(DV ~ spin_habit_group + weekly_play_days + bet_habit_group + cz_group, data = newData) 
```

### Detecting Heteroskedasticity using the bptest command

```{r, warning=FALSE, message=FALSE}
varTest <- bptest(Model)    # lmtest package
regType <- ifelse(varTest$p.value < 0.05, 'HC2', 'classical')
regType
```


## Performing linear regression
```{r, warning=FALSE, message=FALSE}
Model <- lm_robust(DV ~ spin_habit_group + weekly_play_days + bet_habit_group + cz_group, se_type = regType, data = newData)

summary(Model)
```

